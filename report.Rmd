---
title: "Depression Factors Prediction based on DASS Responses Report"
author: "Huanyu Chen (hc3451), Qin Huang (2284), Ou Sha (os2424), Lehan Zou (lz2950), Shaolei Ma (sm5592)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(pheatmap)
library(gtsummary)
library(foreign)
library(MASS)
library(Hmisc)
library(reshape2)
library(car)
library(pROC)
library(effects)

```

## *Data*

### Data Source

**DASS-42 Responses**

Our group applied the dataset from Kaggle Depression, Anxiety, and Stress Scales Responses (can be find [here](https://www.kaggle.com/datasets/lucasgreenwell/depression-anxiety-stress-scales-responses)) for this project. The DASS-42 is a self-report scale consisting of 42 items intended to gauge emotional states related to depression, anxiety, and stress. The primary benefit of utilizing the DASS in a clinical context is its ability to ascertain the specific location of emotional turmoil, contributing to a more comprehensive clinical assessment. Its core function is to evaluate the severity of the fundamental symptoms associated with depression, anxiety, and stress.

```{r}
# Load the dataset
dass_raw = read.csv("./data/data.csv", sep = "\t")
```

The raw data contain `r nrow(dass_raw)` observations and `r ncol(dass_raw)` variables, which contains the information of the participants' responses.

### Data Establishment and Data Cleaning

As we mentioned before, the raw data contains the basic information from the responses. Based on codebook.txt from Kaggle, we checked whether the individual response is meaningful. The criteria are as follow:

-   The survey includes an accuracy check section, which provides several word spelling questions to check whether participants had filled out the questionnaire carefully. `VCL6`,`VCL9`,`VCL12` represents words that not exist. If the participants chose 1 in any of these three questions, the response should be omit.

-   The raw data contains different missing values which needs to be omitted. Specifically, `country` variable has "NONE" as the missing value.

-   `Age` variable have impossible values we need to clean out. For example, 299 years for an age is not reasonable.

```{r}
# kick out meaningless observation
dass = dass_raw %>%
  filter(!(VCL6 == 1 | VCL9 == 1 | VCL12 == 1)) %>%
  filter(!country == "NONE") %>%
  filter(age <= 100)

dass = dass %>%
  dplyr::select(matches('Q\\d+A'), country, education, urban, gender, age, religion, orientation, race, married) %>%
  na.omit()
```

Since we observed that there are some variables have actual meaning corresponding to the original numeric value, we refactor these variables, including `education`, `urban`, `gender`, `religion`, `orientation`, `race`, `married`. In these variables, if the value is 0, it represents missing value and we delete these observations.

```{r}
# refactor the variables
dass_new = dass %>%
  mutate(
    education = case_when(education == 1 ~ 'Less than high school', 
                               education == 2 ~ 'High school', 
                               education == 3 ~ 'University degree', 
                               education == 4 ~ 'Graduate degree'),
    urban = case_when(urban == 1 ~ 'Rural',
                      urban == 2 ~ 'Suburban', 
                      urban == 3 ~ 'Urban'),
    gender = case_when(gender == 1 ~ 'Male',
                       gender == 2 ~ 'Female',
                       gender == 3 ~ 'Other'),
    religion = case_when(religion == 1 ~ 'Agnostic', 
                         religion == 2 ~ 'Atheist', 
                         religion == 3 ~ 'Buddhist', 
                         religion == 4 ~ 'Christian (Catholic)', 
                         religion == 5 ~ 'Christian (Mormon)', 
                         religion == 6 ~ 'Christian (Protestant)', 
                         religion == 7 ~ 'Christian (Other)', 
                         religion == 8 ~ 'Hindu', 
                         religion == 9 ~ 'Jewish', 
                         religion == 10 ~ 'Muslim', 
                         religion == 11 ~ 'Sikh', 
                         religion == 12 ~ 'Other'),
    orientation = case_when(orientation == 1 ~ 'Heterosexual', 
                            orientation == 2 ~ 'Bisexual', 
                            orientation == 3 ~ 'Homosexual', 
                            orientation == 4 ~ 'Asexual', 
                            orientation == 5 ~ 'Other'),
    race = case_when(race == 10 ~ 'Asian', 
                     race == 20 ~ 'Arab', 
                     race == 30 ~ 'Black', 
                     race == 40 ~ 'Indigenous Australian', 
                     race == 50 ~ 'Native American', 
                     race == 60 ~ 'White', 
                     race == 70 ~ 'Other'),
    married = case_when(married == 1 ~ 'Never married', 
                        married == 2 ~ 'Currently married', 
                        married == 3 ~ 'Previously married')
    ) %>%
  na.omit()
```

Based on the scoring criteria (as shown in DASS-42-scoring.pdf), we add up the values for Q3A, Q5A, Q10A, Q13A, Q16A, Q17A, Q21A, Q24A, Q26A, Q31A, Q34A, Q37A, Q38A and Q42A as the depression scores.

Similarly, add up the values for Q2A, Q4A, Q7A, Q9A, Q15A, Q19A, Q20A, Q23A, Q25A, Q28A, Q30A, Q36A, Q40A and Q41A as the anxiety scores and the sum of Q1A, Q6A, Q8A, Q11A, Q12A, Q14A, Q18A, Q22A, Q27A, Q29A, Q32A, Q33A, Q35A and Q39A as the stress scores.

Considering that the scoring criteria we refer to is 0-3 scale but Kaggle dataset is 1-4 scale, we modify these three scores by minus 14.

After that, we could assign depression level, anxiety level and stress level for each observation refer to the rule of:

1.  Depression ï¼ˆscore \~ level)

    -   0 - 9 \~ normal

    -   10 - 13 \~ mild

    -   14 - 20 \~ moderate

    -   21 - 27 \~ severe

    -   \>27 \~ extremely severe

2.  Anxiety

    -   0 - 7 \~ normal

    -   8 - 9 \~ mild

    -   10 - 14 \~ moderate

    -   15 - 19 \~ severe

    -   \>19 \~ extremely severe

3.  Stress

    -   0 - 14 \~ normal

    -   15 - 18 \~ mild

    -   19 - 25 \~ moderate

    -   26 - 33 \~ severe

    -   \>33 \~ extremely severe

Considering that stress, anxiety and depression might have correlations, we apply correlation test for `stress_level`, `depression_level`, `anxiety_level`.

```{r}
dass_heat2 <- dass %>%
  mutate(
    depression = Q3A + Q5A + Q10A + Q13A + Q16A + Q17A + Q21A + Q24A + Q26A + Q31A + Q34A + Q37A + Q38A + Q42A - 14,
    anxiety = Q2A + Q4A + Q7A + Q9A + Q15A + Q19A + Q20A + Q23A + Q25A + Q28A + Q30A + Q36A + Q40A + Q41A - 14,
    stress = Q1A + Q6A + Q8A + Q11A + Q12A + Q14A + Q18A + Q22A + Q27A + Q29A + Q32A + Q33A + Q35A + Q39A - 14
    ) %>%
  mutate(depression = case_when(
    depression >= 0 & depression <= 9 ~ 0,
    depression >= 10 & depression <= 13 ~ 1,
    depression >= 14 & depression <= 20 ~ 2,
    depression >= 21 & depression <= 27 ~ 3,
    depression >= 28 ~ 4
  )) %>%
  mutate(anxiety = case_when(
    anxiety >= 0 & anxiety <= 7 ~ 0,
    anxiety >= 8 & anxiety <= 9 ~ 1,
    anxiety >= 10 & anxiety <= 14 ~ 2,
    anxiety >= 15 & anxiety <= 19 ~ 3,
    anxiety >= 20 ~ 4
  )) %>%
  mutate(stress = case_when(
    stress >= 0 & stress <= 14 ~ 0,
    stress >= 15 & stress <= 18 ~ 1,
    stress >= 19 & stress <= 25 ~ 2,
    stress >= 26 & stress <= 33 ~ 3,
    stress >= 34 ~ 4
  )) %>%
  dplyr::select(depression,anxiety,stress)

r1 <- cor(dass_heat2,
         method = "pearson",
         use = "pairwise.complete.obs"
) 

pheatmap(r1, 
         show_colnames = TRUE,   
         show_rownames=TRUE,    
         fontsize=5,             
         color = colorRampPalette(c('#ffffff','#ff0000'))(100), 
         annotation_legend=TRUE, 
         border_color=NA,        
         scale="none",            
         cluster_rows = F,
         cluster_cols = F,
         breaks = seq(0, 1, length.out = 90)
)
```

According to the heat map, we could conclude that these three variables have strong correlation. Therefore, in our project, we take depression_level as the representative.

Finally, we get our clean and tidy dataset for the project.

```{r}
# create three different dataset
dass_new = dass_new %>%
  mutate(
    depression = Q3A + Q5A + Q10A + Q13A + Q16A + Q17A + Q21A + Q24A + Q26A + Q31A + Q34A + Q37A + Q38A + Q42A - 14
    ) %>%
  mutate(education = factor(education, levels = c('Less than high school', 'High school', 'University degree', 'Graduate degree'))) %>%
  mutate(married = factor(married, levels = c("Previously married", "Currently married", "Never married"))) %>%
  dplyr::select(-matches('Q\\d+A'))

# create das level variables
dass_new = dass_new %>%
  mutate(depression_level = case_when(
    depression >= 0 & depression <= 9 ~ 'Normal',
    depression >= 10 & depression <= 13 ~ 'Mild',
    depression >= 14 & depression <= 20 ~ 'Moderate',
    depression >= 21 & depression <= 27 ~ 'Severe',
    depression >= 28 ~ 'Extremely severe'
  )) %>%
  mutate(depression_level = factor(depression_level, c("Normal","Mild","Moderate","Severe","Extremely severe"))) %>%
  dplyr::select(-depression)

head(dass_new)
```

### Data Summary

Above all, we got our dataset for further analysis. It contains `r nrow(dass_new)` observations and `r ncol(dass_new)` variables. The explanation of each variables are listed below:

-   `country`: The country where the participants from.

-   `education`: The education level of the participants.

-   `urban`: The urban level of the place where participants live.

-   `gender`: The sex of the participants.

-   `religion`: The religion which the participants belong to.

-   `orientation`: The sexual orientation of the participants.

-   `race`: The race of participants.

-   `married`: The marriage status of participants.

-   `age`: The age when participants response the survey.

-   `depression_level`: The depression level of the participants according to the survey and scores.

```{r}



dass_new %>%
  dplyr::select(-country) %>%
  tbl_summary(type = list(
    education ~ "categorical", 
    urban ~ "categorical", 
    gender ~ "categorical",
    religion ~ "categorical",
    orientation ~ "categorical",
    race ~ "categorical",
    married ~ "categorical",
    age ~ "continuous", 
    depression_level ~ "categorical"
  ), 
  statistic = list(all_continuous() ~ "{mean} ({sd})"), 
  digits = all_continuous() ~ 1,
  label = c(
    education = "Education level",
    urban = "Urban level",
    gender = "Gender",
    religion = "Religion",
    orientation = 'Sexual orientation',
    race = 'Race',
    married = 'Marriage status',
    age = "Age (Years)",
    depression_level = "Depression level"
  )) %>%
  bold_labels() %>%
  as_gt()  # Display the table as a gt object

```

## *Exploratory Analysis*

## *Additional Analysis*

## *Regression*

We want to investigate the relationship between demographic variables and depression levels. Because the dependent variable depression_level is an ordinal variable with five levels ("Normal", "Mild", "Moderate", "Severe", "Extremely severe"), we choose to fit an *ordered logit model*.

### Independent Variables

Imbalanced data may result in an inaccurate outcome due to a small sample size in some classes. Therefore, we first want to test the distribution of independent variables to avoid the imbalance of samples between different categories.

```{r}
dass_new = read_csv("data/dass_new.csv")

dass_new |> 
  dplyr::select(age, everything()) |> 
  mutate(across(country:depression_level, factor)) |> 
  summary()
```

Some categories contain few samples (e.g. countries other than the listed six countries have less than 500 samples). For the efficacy of the model and considering which class most interests us, we regroup the independent variables following the standards below:

-   `country`: Group the country with less than 500 samples into "Other", and set "US" to be the reference level.
-   `education`: Order the variable by the length of education.
-   `race`: We follow [standards on race and ethnicity](https://www.govinfo.gov/content/pkg/FR-1997-10-30/pdf/97-28653.pdf) to include only "Asian", "Black", "Native American", "White", and make other categories "Other". We set "White" to be the reference level.
-   `religion`: We conclude "Christian (Catholic)", "Christian (Mormon)", "Christian (Other)", "Christian (Protestant)" into "Christian", and set it as the reference level.
-   `orientation`: Set the "Heterosexual" to be the reference level.
-   `married`: Order the variable by marriage status.

```{r}
dass_fit_df =
  dass_new |> 
  mutate(
    country = relevel(as.factor(ifelse(country %in% c("MY", "US", "GB", "CA", "ID", "PH"), country, "Other")), ref = "US"),
    education = factor(education, levels = c("Less than high school", "High school", "University degree", "Graduate degree")),
    race = relevel(as.factor(ifelse(race %in% c("Arab", "Indigenous Australian"), "Other", race)), ref = "White"),
    religion = relevel(as.factor(ifelse(substr(religion, 1, 9) == "Christian", "Christian", religion)), "Christian"),
    orientation = relevel(as.factor(orientation), "Heterosexual"),
    married = factor(married, levels = c("Never married", "Currently married", "Previously married")),
    depression_level = factor(depression_level, levels = c("Normal", "Mild", "Moderate", "Severe", "Extremely severe"))
  )

dass_fit_df |> summary()
```

### Model Fitting

First fit a model without variables selection.

```{r}
dass_fit =
  dass_fit_df |> 
  polr(depression_level ~ ., data = _)

(fit_s = 
  dass_fit |> 
  summary())
```

When conducting an ordered logit model, the underlying assumption is that the coefficients that describe the relationship between, say, the lowest versus all higher categories of the response variable are the same as those that describe the relationship between the next lowest category and all higher categories, etc. This is called the proportional odds assumption or the parallel assumption.

Now, we want to test if the model conducted meets the parallel assumption.

```{r}
car::poTest(dass_fit)
```

Because the overall $p-value < 0.001$, we reject the null hypothesis and conclude that the parallel assumption is not met.

To meet the parallel assumption, considering the variables of interest in EDA, we try the following two methods:

-   **Select independent variables**: Because we think `religion` and `race`, `married` and `orientation`, `country` and `urban` are strongly correlated with each other, and we care more about `race`, `orientation`, and `country`, first delete `religion`, `married`, and `urban`. We also delete `education` to meet the parallel assumption.
-   **Regroup dependent variable**: Regroup `depression_level` into "Moderate or Below", "Severe", "Extremely severe".

```{r}
dass_fit_df =
  dass_fit_df |> 
  mutate(depression_level = factor(case_match(
    depression_level,
    "Normal" ~ "Moderate or Below",
    "Mild" ~ "Moderate or Below","Moderate" ~ "Moderate or Below",
    "Severe" ~ "Severe",
    "Extremely severe" ~ "Extremely severe"
   ), level = c("Moderate or Below", "Severe", "Extremely severe")))

dass_fit1 =
  dass_fit_df |> 
  polr(depression_level ~ country + gender + age + orientation + race, data = _)

dass_fit1 |> poTest()
```

The model meets the parallel assumption at $\alpha=0.05$ level (with an overall $p = 0.067 > 0.05$).

#### Depression Levels Distribution

After selecting independent variables, we can further visualize the data based on the effective covariates as well as the good stratum of depression level.

```{r, fig.width=20, fig.height=10, message = FALSE}
# Create a data frame with the predictor values for visualization
predictor_data <- model.matrix(depression_level ~ country + gender + age
                               + orientation + race, data = dass_fit_df)

# Compute the effects
effects <- allEffects(dass_fit1, xlevels = list(predictor_data))

# Plot the effects
plot(effects, style = "stacked")
```

The accompanying graphs display the probability of depression levels across various categorical and continuous variables. For instance, the trend depicted in the graph indicates higher rates of extreme depression among young people.

### Results

```{r}
dass_fit1 |> summary()
```

The estimated model can be written as: \begin{align*}
\text{logit}(\hat P(\text{Depression Level} \leq \text{Severe})) &= -0.69 \\
&+ 0.18 \times I(\text{country} = \text{CA}) \\
&+ 0.20 \times I(\text{country} = \text{GB}) \\
&- 0.04 \times I(\text{country} = \text{ID}) \\
&- 0.19 \times I(\text{country} = \text{MY}) \\
&+ 0.13 \times I(\text{country} = \text{PH}) \\
&+ 0.11 \times I(\text{country} = \text{Other}) \\
&- 0.10 \times I(\text{gender} = \text{Male}) \\
&+ 0.38 \times I(\text{gender} = \text{Other}) \\
&- 0.03 \times \text{age} \\
&+ 0.23 \times I(\text{orientation} = \text{Asexual}) \\
&+ 0.40 \times I(\text{orientation} = \text{Bisexual}) \\
&+ 0.30 \times I(\text{orientation} = \text{Homosexual}) \\
&+ 0.22 \times I(\text{orientation} = \text{Other}) \\
&- 0.16 \times I(\text{race} = \text{Asian}) \\
&- 0.09 \times I(\text{race} = \text{Black}) \\
&+ 0.11 \times I(\text{race} = \text{Native American}) \\
&- 0.10 \times I(\text{race} = \text{Other})
\end{align*}

```{=tex}
\begin{align*}
\text{logit}(\hat P(\text{Depression Level} \leq \text{Extremely Severe})) &= 0.01 \\
&+ 0.18 \times I(\text{country} = \text{CA}) \\
&+ 0.20 \times I(\text{country} = \text{GB}) \\
&- 0.04 \times I(\text{country} = \text{ID}) \\
&- 0.19 \times I(\text{country} = \text{MY}) \\
&+ 0.13 \times I(\text{country} = \text{PH}) \\
&+ 0.11 \times I(\text{country} = \text{Other}) \\
&- 0.10 \times I(\text{gender} = \text{Male}) \\
&+ 0.38 \times I(\text{gender} = \text{Other}) \\
&- 0.03 \times \text{age} \\
&+ 0.23 \times I(\text{orientation} = \text{Asexual}) \\
&+ 0.40 \times I(\text{orientation} = \text{Bisexual}) \\
&+ 0.30 \times I(\text{orientation} = \text{Homosexual}) \\
&+ 0.22 \times I(\text{orientation} = \text{Other}) \\
&- 0.16 \times I(\text{race} = \text{Asian}) \\
&- 0.09 \times I(\text{race} = \text{Black}) \\
&+ 0.11 \times I(\text{race} = \text{Native American}) \\
&- 0.10 \times I(\text{race} = \text{Other})
\end{align*}
```

Calculate the odds ratio and CI for variables:

```{r}
# exp(cbind(OR = coef(dass_fit1), confint(dass_fit1))) |> 
#   knitr::kable()
```

#### Receiver Operating Characteristic Curve for Depression Level

At this stage, we would like to draw a receiver operating characteristic (ROC) curve for depression level to check the model fit.

```{r}

# Predicting probabilities for all classes
predicted_probs <- predict(dass_fit1, type = "probs")

# Extracting the response variable
response <- ifelse(dass_fit_df$depression_level == "Moderate or Below", 1,
                   ifelse(dass_fit_df$depression_level == "Severe", 2, 3))

# Calculating ROC curves for three responses
roc_obj_1 <- roc(as.numeric(response == 1), predicted_probs[, "Moderate or Below"])
roc_obj_2 <- roc(as.numeric(response == 2), predicted_probs[, "Severe"])
roc_obj_3 <- roc(as.numeric(response == 3), predicted_probs[, "Extremely severe"])

# Plotting ROC curves for three responses on the same graph
plot(roc_obj_1, col = "blue", main = "ROC Curves for Three Responses")
plot(roc_obj_2, col = "red", add = TRUE)
plot(roc_obj_3, col = "green", add = TRUE)
legend("bottomright",
       legend = c("Moderate or Below", "Severe", "Extremely Severe"),
       col = c("blue", "red", "green"), lty = 1)
```

Looking at the ROC curves, it is clear that both the "Moderate or Below" and "Extremely Severe" categories show good performance and are close to the upper left corner, indicating effective performance in discriminating between these categories. However, the performance of the "Severe" category suggests an available but less significant trend compared to the above two categories. The positioning of this curve indicates room for improvement, implying a need for more data points representing individuals with a "severe" level of depression. Expanding the data set to include additional instances characterized by a "Severe" level of depression could improve the model's ability to discriminate and accurately predict within this specific category.

### Interpretation

#### Continuous Variable

##### Age

-   For every one unit increase in participant's age, the odds of having a more severe depression level is multiplied 0.98 times, holding constant all other variables. It indicates that older people may have less risk to get depressed.

#### Categorical Variables

##### Country

```{r}
# Extract coefficients for countries
pos_country = str_starts(names(dass_fit1$coefficients), "country")

country_coefficients =
  tibble(
    country = substr(names(dass_fit1$coefficients)[pos_country], 8, 20),
    OR = exp(dass_fit1$coefficients[pos_country])
  ) |> 
  mutate(country = fct_reorder(country, OR))
  

# Plotting coefficients for countries
ggplot(country_coefficients, aes(x = country, y = OR - 1)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Effect of Countries on Depression Levels",
       x = "Country", y = "OR - 1")
```

-   For Canadian, Britain, and Philippines participants, the odds of having a more severe depression level is higher than that of US participants, holding constant all other variables.
-   For Indonesia and Malaysia participants, the odds of having a more severe depression level is lower than that of US participants, holding constant all other variables.

##### Gender

```{r}
# Extract coefficients for Gender
pos_gender = str_starts(names(dass_fit1$coefficients), "gender")

gender_coefficients =
  tibble(
    gender = substr(names(dass_fit1$coefficients)[pos_gender], 7, 20),
    OR = exp(dass_fit1$coefficients[pos_gender])
  ) |> 
  mutate(gender = fct_reorder(gender, OR))

# Plotting coefficients for Gender
ggplot(gender_coefficients, aes(x = gender, y = OR - 1)) +
  geom_bar(stat = "identity", fill = "#d8b4e2", color = "black") +
  labs(title = "Effect of Gender on Depression Levels",
       x = "Gender", y = "OR - 1")
```

-   For male participants, the odds of having a more severe depression level is 0.90 times that of female participants, holding constant all other variables.
-   For non-binary participants, the odds of having a more severe depression level is 1.47 times that of female participants, holding constant all other variables.

##### Race

```{r}
# Extract coefficients for races
pos_race <- str_starts(names(dass_fit1$coefficients), "race")

race_coefficients =
  tibble(
    race = substr(names(dass_fit1$coefficients)[pos_race], 5, 20),
    OR = dass_fit1$coefficients[pos_race]
  ) |> 
  mutate(race = fct_reorder(race, OR))

# Plotting coefficients for races
ggplot(race_coefficients, aes(x = race, y = OR - 1)) +
  geom_bar(stat = "identity", fill = "pink", color = "black") +
  labs(
    title = "Effect of Races on Depression Levels",
    x = "Race",
    y = "OR - 1"
  )
```

-   For Native American, Asian, Black, and Other participants, the odds of having a more severe depression level is lower than that of White participants, holding constant all other variables.

##### Orientation

```{r}
# Extract coefficients for orientations
pos_orientation <- str_starts(names(dass_fit1$coefficients), "orientation")

orientation_coefficients <- data.frame(
  orientation = substr(names(dass_fit1$coefficients)[pos_orientation], 12, 20),
  OR = exp(dass_fit1$coefficients[pos_orientation])
)

# Plotting coefficients for orientations
ggplot(orientation_coefficients, aes(x = orientation, y = OR - 1)) +
  geom_bar(stat = "identity", fill = "palegreen", color = "black") +
  labs(
    title = "Effect of Orientations on Depression Levels",
    x = "Orientation",
    y = "OR - 1"
  )
```

-   For sexual minorities, the odds of having a more severe depression level is higher than that of heterosexual orientation participants, holding constant all other variables.


## *Discussion*

### Challenge

### Limitation

### Future work

First, we would like to filter, check validity, and eliminate incompetent data; then, we would score each person's depression levels. Our group plans to use box plots and/or scatter plots to show the distributions among different variables. We would apply chi-squared test to compare the distribution of different factors within depression levels. Based on the levels, we would also apply regression models to figure out the possible factors, including age, sex, location, etc, leading to depression. Understanding survey questions, as well as cleaning and tidying the dataset into a readable format is one of our current coding challenges.

## *Reference*
